{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mADd6iSDCmLs"
      },
      "source": [
        "# Decision Tree Lab"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "CGsI9XEJCmLv"
      },
      "outputs": [],
      "source": [
        "from sklearn.base import BaseEstimator, ClassifierMixin\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from scipy.io import arff\n",
        "import matplotlib.pyplot as plt\n",
        "from scipy import stats\n",
        "import arff as arf\n",
        "import math\n",
        "import random"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Node Class"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [],
      "source": [
        "class Node:\n",
        "  def __init__(self, inputs, outputs, counts, features_used=[]):\n",
        "    self.inputs = inputs\n",
        "    self.outputs = outputs\n",
        "    self.counts = counts\n",
        "    self.children = []\n",
        "    self.features_used = features_used\n",
        "    # initial info of each node\n",
        "    self.info  = self.calc_info()\n",
        "    # will be used for leaf nodes, all other nodes will have none\n",
        "    self.prediction= None\n",
        "    \n",
        "  def generate_children(self):\n",
        "    # indicating the number of columns\n",
        "    for i in range(len(self.inputs[0])):\n",
        "      # if we havent already split/seen this feature\n",
        "      if i not in self.features_used:\n",
        "        # initialize the next children for this node\n",
        "        next_children = []\n",
        "        # indicating the number of values for this feature\n",
        "        for j in range(self.counts[i]):\n",
        "          # initialize temp inputs and outputs. we will use these arrays to set as inputs and outputs for the next node\n",
        "          tmp_inputs = []\n",
        "          tmp_outputs = []\n",
        "          # loop though all of the inputs to add to the tmp arrays\n",
        "          for k in range(len(self.inputs)):\n",
        "            # filtering the input values we are adding to tmp arrays\n",
        "            if self.inputs[k][i] == j:\n",
        "              tmp_inputs.append(self.inputs[k])\n",
        "              tmp_outputs.append(self.outputs[k])\n",
        "          # if there were inputs to add, create a new node\n",
        "          if len(tmp_inputs) != 0:\n",
        "            new_node = Node(tmp_inputs, tmp_outputs, self.counts, np.concatenate((self.features_used, [i])))\n",
        "            # setting the feature and feature index, keeping track of where we are so we know where to go\n",
        "            new_node.set_feature(j)\n",
        "            new_node.set_feature_index(i)\n",
        "            next_children.append(new_node)\n",
        "        if len(self.children) == 0:\n",
        "          self.children = next_children\n",
        "        else:\n",
        "          # get the current split info and next split info\n",
        "          curr_split_gain = self.calc_children_info(self.children)\n",
        "          next_split_gain = self.calc_children_info(next_children)\n",
        "          # if there is more info gain on next split, split here with this nodes children\n",
        "          if next_split_gain > curr_split_gain:\n",
        "            self.children = next_children\n",
        "    return self.calc_children_info(self.children)\n",
        "\n",
        "  def calc_children_info(self, children):\n",
        "    info = self.info\n",
        "    for i in range(len(children)):\n",
        "      info -= (len(children[i].inputs) / len(self.inputs) * children[i].get_info())\n",
        "    return info\n",
        "    \n",
        "  def set_feature(self, num):\n",
        "    self.feature = num\n",
        "    return\n",
        "\n",
        "  def set_feature_index(self, num):\n",
        "    self.feature_index = num\n",
        "    return\n",
        "\n",
        "  def get_num_feat_used(self):\n",
        "    return len(self.features_used)\n",
        "\n",
        "  def predict_node(self):\n",
        "    # if info is zero, prediction will be first index of nodes output array\n",
        "    if self.get_info() == 0:\n",
        "      self.prediction = self.outputs[0]\n",
        "    else:\n",
        "      self.prediction = stats.mode(self.inputs).mode[0][0]\n",
        "\n",
        "  def get_children(self):\n",
        "    return self.children\n",
        "\n",
        "  def calc_info(self):\n",
        "    info = 0\n",
        "    # calculate information gained\n",
        "    ent_arr = np.zeros(self.counts[-1])\n",
        "    for i in range(len(self.outputs)):\n",
        "      ent_arr[self.outputs[i]] += 1\n",
        "    ent_arr = ent_arr / len(self.inputs)\n",
        "    for child in ent_arr:\n",
        "      if child != 0:\n",
        "          info += (-child) * math.log(child, 2)\n",
        "    if len(ent_arr) == 0:\n",
        "      self.prediction = self.outputs[0]\n",
        "    return info\n",
        "\n",
        "  def get_info(self):\n",
        "    return self.info\n",
        "\n",
        "  def get_attr_index(self):\n",
        "    return self.children_attr_index[self.index]\n",
        "\n",
        "  # passing -1 for layer of root node\n",
        "  def print_tree(self, layer):\n",
        "    # need to print a indentation for the number of layer we are on\n",
        "    for i in range(layer):\n",
        "      print(\"   \",end=\"\")\n",
        "    # if we are passed the root node, print out the feature and feature index\n",
        "    if layer >= 0:\n",
        "      print('feature ', end=\"\")\n",
        "      print(self.feature_index, end=\"\")\n",
        "      print(' = ', end=\"\")\n",
        "      print(self.feature, end=\"\")\n",
        "      print(':')\n",
        "    # if we are at a leaf node, print out the prediction\n",
        "    if self.prediction != None:\n",
        "      for i in range(layer+1):\n",
        "        print(\"   \", end=\"\")\n",
        "      print('prediction: ' + str(self.prediction))\n",
        "    else:\n",
        "      # loop through all children and print out information\n",
        "      num_ch = len(self.get_children())\n",
        "      for i in range(num_ch):\n",
        "        self.get_children()[i].print_tree(layer+1)\n",
        "    return\n",
        "    \n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wgq5w2mOCmLw"
      },
      "source": [
        "## 1. (40%) Correctly implement the ID3 decision tree algorithm, including the ability to handle unknown attributes (You do not need to handle real valued attributes).  \n",
        "### Code Requirements/Notes:\n",
        "- Use standard information gain as your basic attribute evaluation metric.  (Note that normal ID3 would usually augment information gain with gain ratio or some other mechanism to penalize statistically insignificant attribute splits. Otherwise, even with approaches like pruning below, the SSE type of overfit could still hurt us.) \n",
        "- You are welcome to create other classes and/or functions in addition to the ones provided below. (e.g. If you build out a tree structure, you might create a node class).\n",
        "- It is a good idea to use a simple data set (like the lenses data or the pizza homework), which you can check by hand, to test your algorithm to make sure that it is working correctly. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "XtB9lCVaCmLw"
      },
      "outputs": [],
      "source": [
        "class DTClassifier(BaseEstimator,ClassifierMixin):\n",
        "\n",
        "    def __init__(self,counts=None):\n",
        "        \"\"\" Initialize class with chosen hyperparameters.\n",
        "        Args:\n",
        "        Optional Args (Args we think will make your life easier):\n",
        "            counts: A list of Ints that tell you how many types of each feature there are\n",
        "        Example:\n",
        "            DT  = DTClassifier()\n",
        "            or\n",
        "            DT = DTClassifier(count = [2,3,2,2])\n",
        "            Dataset = \n",
        "            [[0,1,0,0],\n",
        "            [1,2,1,1],\n",
        "            [0,1,1,0],\n",
        "            [1,2,0,1],\n",
        "            [0,0,1,1]]\n",
        "\n",
        "        \"\"\" \n",
        "        self.counts = counts\n",
        "        # used to save info gain through the fit process\n",
        "        self.info_gain =[]\n",
        "\n",
        "    def print_tree(self):\n",
        "        self.root_node.print_tree(-1)\n",
        "\n",
        "    def fit_and_score(self, fullData):\n",
        "        # split up targets and inputs\n",
        "        train = np.array(fullData[:,0:-1])\n",
        "        targets = np.array(fullData[:,-1])\n",
        "        # fit data\n",
        "        self.fit(train, targets)\n",
        "        return\n",
        "\n",
        "    def fit(self, X, y):\n",
        "        \"\"\" Fit the data; Make the Decision tree\n",
        "\n",
        "        Args:\n",
        "            X (array-like): A 2D numpy array with the training data, excluding targets\n",
        "            y (array-like): A 1D numpy array with the training targets\n",
        "\n",
        "        Returns:\n",
        "            self: this allows this to be chained, e.g. model.fit(X,y).predict(X_test)\n",
        "\n",
        "        \"\"\"\n",
        "        # set number of features and root node class variables\n",
        "        self.num_features = len(X[0])\n",
        "        self.root_node = Node(X, y, self.counts, features_used=[])\n",
        "\n",
        "        # start splitting the tree from root node\n",
        "        self.split_tree(self.root_node)\n",
        "        \n",
        "        return self\n",
        "\n",
        "    def split_tree(self, node):\n",
        "        # how we know when we are done\n",
        "        if node.get_info() != 0 and node.get_num_feat_used() < self.num_features:\n",
        "            # get info gained at the split\n",
        "            info = node.generate_children()\n",
        "            self.info_gain.append(info)\n",
        "            # get children of current node\n",
        "            children = node.get_children()\n",
        "            for i in range(len(children)):\n",
        "                # loop through children to split tree\n",
        "                if len(node.get_children()[i].inputs) != 0:\n",
        "                    self.split_tree(node.get_children()[i])\n",
        "        else:\n",
        "            # at a leaf node, need to do prediction\n",
        "            node.predict_node()\n",
        "    \n",
        "    def predict_helper(self, node, pattern):\n",
        "        # BASE CASE- if we are at the leaf node return its prediction\n",
        "        if node.prediction != None:\n",
        "            return node.prediction\n",
        "        else:\n",
        "            children = node.get_children()\n",
        "            feat_ind = children[0].feature_index\n",
        "            pat_val = pattern[feat_ind]\n",
        "            n_node = None\n",
        "            for i in range(len(children)):\n",
        "                if children[i].feature == pat_val:\n",
        "                    n_node = children[i]\n",
        "                    break\n",
        "            # need to choose a random child node incase we aren't done yet\n",
        "            if n_node == None:\n",
        "                rand = random.randint(0, len(children) - 1)\n",
        "                n_node = children[rand]\n",
        "        # recursive call to traverse tree\n",
        "        return self.predict_helper(n_node, pattern)\n",
        "\n",
        "\n",
        "    def predict(self, X):\n",
        "        \"\"\" Predict all classes for a dataset X\n",
        "\n",
        "        Args:\n",
        "            X (array-like): A 2D numpy array with the training data, excluding targets\n",
        "\n",
        "        Returns:\n",
        "            array, shape (n_samples,)\n",
        "                Predicted target values per element in X.\n",
        "        \"\"\"\n",
        "        preds = []\n",
        "        # append predictions of each row in x by traversing tree\n",
        "        for i in range(len(X)):\n",
        "            preds.append(self.predict_helper(self.root_node, X[i]))\n",
        "        return preds\n",
        "\n",
        "\n",
        "    def score(self, X, y):\n",
        "        \"\"\" Return accuracy(Classification Acc) of model on a given dataset. Must implement own score function.\n",
        "\n",
        "        Args:\n",
        "            X (array-like): A 2D numpy array with data, excluding targets\n",
        "            y (array-like): A 1D numpy array of the targets \n",
        "        \"\"\"\n",
        "        # get predictions array\n",
        "        predictions = self.predict(X)\n",
        "        total = len(y)\n",
        "        correct = 0\n",
        "        # compare with actual outputs\n",
        "        for i in range(len(predictions)):\n",
        "            if predictions[i] == y[i]:\n",
        "                correct +=1\n",
        "        # return percentage correct\n",
        "        return correct/total\n",
        "        \n",
        "    # returns array of info gain at each split \n",
        "    def get_split_info_gain(self):\n",
        "        return self.info_gain\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Helper Functions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [],
      "source": [
        "# HELPER FUNCTIONS\n",
        "\n",
        "def convertBytestoString(df):\n",
        "  for col in df:\n",
        "    if isinstance(df[col][0], bytes):\n",
        "      df[col] = df[col].str.decode(\"utf8\")\n",
        "  return df\n",
        "\n",
        "def get_counts(dataset):\n",
        "  counts = []\n",
        "  for column in dataset:\n",
        "    counts.append(len(dataset[column].value_counts()))\n",
        "  return counts\n",
        "\n",
        "def handle_missing(dataset):\n",
        "  # calculate mode, replacing missing values with mode\n",
        "  mode = dataset.mode().to_numpy().flatten()\n",
        "  data_columns = len(dataset.columns.to_numpy())\n",
        "\n",
        "  new_dataset = dataset.to_numpy()\n",
        "  length = len(new_dataset)\n",
        "  for i in range(length):\n",
        "    # loop through columns looking for missing values\n",
        "    for j in range(data_columns):\n",
        "      # missing with question mark and np.nan\n",
        "      if new_dataset[i][j] == '?' or new_dataset[i][j] == np.nan:\n",
        "        new_dataset[i][j] = mode[j]\n",
        "  return new_dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Dataset Constants"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {},
      "outputs": [],
      "source": [
        "# for cleaning lenses dataset\n",
        "lenses_dict = {\"age\": {\"young\": 2, \"pre_presbyopic\": 1, \"presbyopic\": 0},\n",
        "    \"spectacle_prescrip\": {\"myope\": 1, \"hypermetrope\": 0},\n",
        "    \"astigmatism\": {\"no\": 0, \"yes\": 1},\n",
        "    \"tear_prod_rate\" : {\"reduced\" : 1, \"normal\" : 0 },\n",
        "    \"contact_lenses\" : {\"none\": 1, \"soft\": 2, \"hard\": 0}}\n",
        "\n",
        "# for cleaning zoo dataset\n",
        "zoo_dict = {\"hair\":     {\"F\": 0, \"T\": 1},\n",
        "    \"feathers\": {\"F\": 0, \"T\": 1},\n",
        "    \"eggs\": {\"F\": 0, \"T\": 1},\n",
        "    \"milk\": {\"F\": 0, \"T\": 1},\n",
        "    \"airborne\": {\"F\": 0, \"T\": 1},\n",
        "    \"predator\": {\"F\": 0, \"T\": 1},\n",
        "    \"aquatic\": {\"F\": 0, \"T\": 1},\n",
        "    \"toothed\": {\"F\": 0, \"T\": 1},\n",
        "    \"backbone\": {\"F\": 0, \"T\": 1},\n",
        "    \"breathes\": {\"F\": 0, \"T\": 1},\n",
        "    \"venomous\": {\"F\": 0, \"T\": 1},\n",
        "    \"fins\": {\"F\": 0, \"T\": 1},\n",
        "    \"legs\": {\"0\": 0, \"2\": 1, \"4\": 2, \"5\": 3, \"6\": 4, \"8\": 5},\n",
        "    \"tails\": {\"F\": 0, \"T\": 1},\n",
        "    \"domestic\": {\"F\": 0, \"T\": 1},\n",
        "    \"catsize\": {\"F\": 0, \"T\": 1},\n",
        "    \"type\": {\"cT\": 0, \"c2\": 1, \"c3\": 2, \"c4\": 3, \"c5\": 4, \"c6\": 5,\"c7\": 6}}\n",
        "\n",
        "# for cleaning cars dataset\n",
        "cars_dict = {\"buying\": {\"vhigh\": 0, \"high\": 1, \"med\": 2, \"low\": 3},\n",
        "    \"maint\": {\"vhigh\": 0, \"high\": 1, \"med\": 2, \"low\": 3},\n",
        "    \"doors\": {\"2\": 0, \"3\": 1, \"4\": 2, \"5more\": 3},\n",
        "    \"persons\": {\"2\": 0, \"4\": 1, \"more\": 2},\n",
        "    \"lug_boot\": {\"small\": 0, \"med\": 1, \"big\": 2},\n",
        "    \"safety\": {\"low\": 0, \"med\": 1, \"high\": 2},\n",
        "    \"class\": {\"unacc\": 0, \"acc\": 1, \"good\": 2, \"vgood\": 3}}\n",
        "\n",
        "car_columns = [\"buying\",\"maint\", \"doors\", \"persons\", \"lug_boot\", \"safety\", \"class\"]\n",
        "\n",
        "# for cleaning voting dataset\n",
        "voting_dict = {'handicapped-infants': { 'n':0, 'y':1},\n",
        "                'water-project-cost-sharing' : { 'n':0, 'y':1},\n",
        "                'adoption-of-the-budget-resolution' : { 'n':0, 'y':1},\n",
        "                'physician-fee-freeze' : { 'n':0, 'y':1},\n",
        "                'el-salvador-aid' : { 'n':0, 'y':1},\n",
        "                'religious-groups-in-schools': { 'n':0, 'y':1},\n",
        "                'anti-satellite-test-ban' : { 'n':0, 'y':1},\n",
        "                'aid-to-nicaraguan-contras' : { 'n':0, 'y':1},\n",
        "                'mx-missile' : { 'n':0, 'y':1},\n",
        "                'immigration' : { 'n':0, 'y':1},\n",
        "                'synfuels-corporation-cutback' : { 'n':0, 'y':1},\n",
        "                'education-spending' : { 'n':0, 'y':1},\n",
        "                'superfund-right-to-sue' : { 'n':0, 'y':1},\n",
        "                'crime' : { 'n':0, 'y':1},\n",
        "                'duty-free-exports' : { 'n':0, 'y':1},\n",
        "                'export-administration-act-south-africa' : { 'n':0, 'y':1},\n",
        "                'Class' : { 'democrat':0, 'republican':1}}\n",
        "    "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dybGas3ACmLx"
      },
      "source": [
        "## 1.1 Debug\n",
        "\n",
        "Debug your model by training on the lenses dataset: [Debug Dataset](https://raw.githubusercontent.com/cs472ta/CS472/master/datasets/lenses.arff)\n",
        "\n",
        "Test your model on the lenses test set: [Debug Test Dataset](https://raw.githubusercontent.com/cs472ta/CS472/master/datasets/lenses_test.arff)\n",
        "\n",
        "Parameters:\n",
        "(optional) counts = [3,2,2,2] (You should compute this when you read in the data, before fitting)\n",
        "\n",
        "---\n",
        "\n",
        "Expected Results: Accuracy = [0.33]\n",
        "\n",
        "Predictions should match this file: [Lenses Predictions](https://raw.githubusercontent.com/cs472ta/CS472/master/debug_solutions/pred_lenses.csv)\n",
        "\n",
        "*NOTE: The [Lenses Prediction](https://raw.githubusercontent.com/cs472ta/CS472/master/debug_solutions/pred_lenses.csv) uses the following encoding: soft=2, hard=0, none=1. If your encoding is different, then your output will be different, but not necessarily incorrect.*\n",
        "\n",
        "Split Information Gains (These do not need to be in this exact order):\n",
        "\n",
        "[0.5487949406953987, 0.7704260414863775, 0.3166890883150208, 1.0, 0.4591479170272447, 0.9182958340544894]\n",
        "\n",
        "<!-- You should be able to get about 68% (61%-82%) predictive accuracy on the lenses data -->\n",
        "\n",
        "Here's what your decision tree splits should look like, and the corresponding child node predictions:\n",
        "\n",
        "Decision Tree:\n",
        "<pre>\n",
        "tear_prod_rate = normal:\n",
        "    astigmatism = no:\n",
        "        age = pre_presbyopic:\n",
        "            prediction: soft\n",
        "        age = presbyopic:\n",
        "            spectacle_prescrip = hypermetrope:\n",
        "                prediction: soft\n",
        "            spectacle_prescrip = myope:\n",
        "                prediction: none\n",
        "        age = young:\n",
        "            prediction: soft\n",
        "    astigmatism = yes:\n",
        "        spectacle_prescrip = hypermetrope:\n",
        "            age = pre_presbyopic:\n",
        "                prediction: none\n",
        "            age = presbyopic:\n",
        "                prediction: none\n",
        "            age = young:\n",
        "                prediction: hard\n",
        "        spectacle_prescrip = myope:\n",
        "            prediction: hard\n",
        "tear_prod_rate = reduced:\n",
        "    prediction: none\n",
        "</pre>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DSNiejBECmLy",
        "outputId": "fbc5a652-3c8e-479d-a0a6-28b1d184c83e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "feature 3 = 0:\n",
            "   feature 2 = 0:\n",
            "      feature 0 = 0:\n",
            "         feature 1 = 0:\n",
            "            prediction: 2\n",
            "         feature 1 = 1:\n",
            "            prediction: 1\n",
            "      feature 0 = 1:\n",
            "         prediction: 2\n",
            "      feature 0 = 2:\n",
            "         prediction: 2\n",
            "   feature 2 = 1:\n",
            "      feature 1 = 0:\n",
            "         feature 0 = 0:\n",
            "            prediction: 1\n",
            "         feature 0 = 1:\n",
            "            prediction: 1\n",
            "         feature 0 = 2:\n",
            "            prediction: 0\n",
            "      feature 1 = 1:\n",
            "         prediction: 0\n",
            "feature 3 = 1:\n",
            "   prediction: 1\n",
            "\n",
            "\n",
            "acc:  0.3333333333333333 \n",
            "\n",
            "Split info gain\n",
            "[0.5487949406953985, 0.7704260414863777, 0.3166890883150208, 1.0, 0.4591479170272448, 0.9182958340544896]\n"
          ]
        }
      ],
      "source": [
        "# Load debug training data \n",
        "!curl -s https://raw.githubusercontent.com/cs472ta/CS472/master/datasets/lenses.arff --output lenses.arff\n",
        "    \n",
        "debug_data = arff.loadarff('lenses.arff')\n",
        "lenses_df = pd.DataFrame(debug_data[0])\n",
        "\n",
        "# need to fix columns to be strings\n",
        "lenses_df = convertBytestoString(lenses_df)\n",
        "\n",
        "lenses_df = lenses_df.replace(lenses_dict)\n",
        "\n",
        "# Convert to numpy\n",
        "lenses_np = lenses_df.to_numpy()\n",
        "counts = get_counts(lenses_df)\n",
        "\n",
        "# Train Decision Tree\n",
        "clf = DTClassifier(counts=counts)\n",
        "acc = clf.fit_and_score(lenses_np)\n",
        "clf.print_tree()\n",
        "print(\"\\n\")\n",
        "\n",
        "\n",
        "# Load debug test data\n",
        "!curl -s https://raw.githubusercontent.com/cs472ta/CS472/master/datasets/lenses_test.arff --output debug_test.arff\n",
        "\n",
        "debug_test = arff.loadarff('debug_test.arff')\n",
        "debug_test_df = pd.DataFrame(debug_test[0])\n",
        "\n",
        "lenses_test_df = convertBytestoString(debug_test_df)\n",
        "lenses_test_df = lenses_test_df.replace(lenses_dict)\n",
        "\n",
        "# Convert to numpy\n",
        "lenses_np_test = lenses_test_df.to_numpy()\n",
        "\n",
        "# Predict and compute model accuracy\n",
        "prediction = clf.predict(lenses_np_test[:,0:len(counts)-1])\n",
        "acc = clf.score(lenses_np_test[:,0:], lenses_np_test[:,len(counts)-1:])\n",
        "print(\"acc: \", acc, \"\\n\")\n",
        "\n",
        "# Print the information gain of every split you make.\n",
        "print(\"Split info gain\")\n",
        "print(clf.get_split_info_gain())\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XGU8PK2xCmLz"
      },
      "source": [
        "## 1.2 Evaluation\n",
        "\n",
        "We will evaluate your model based on its performance on the zoo dataset. \n",
        "\n",
        "Train your model using this dataset: [Evaluation Train Dataset](https://raw.githubusercontent.com/cs472ta/CS472/master/datasets/zoo.arff)\n",
        "\n",
        "Test your model on this dataset: [Evaluation Test Dataset](https://raw.githubusercontent.com/cs472ta/CS472/master/datasets/zoo_test.arff)\n",
        "\n",
        "Parameters:\n",
        "(optional) counts = [2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 6, 2, 2, 2] (You should compute this when you read in the data, before fitting)\n",
        "\n",
        "---\n",
        "Print out your accuracy on the evaluation test dataset.\n",
        "\n",
        "Print out the information gain of every split you make."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "xBr3I6jXCmL0"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "feature 12 = 0:\n",
            "   feature 11 = 0:\n",
            "      feature 7 = 0:\n",
            "         prediction: 6\n",
            "      feature 7 = 1:\n",
            "         prediction: 2\n",
            "   feature 11 = 1:\n",
            "      feature 2 = 0:\n",
            "         prediction: 0\n",
            "      feature 2 = 1:\n",
            "         prediction: 3\n",
            "feature 12 = 1:\n",
            "   feature 0 = 0:\n",
            "      prediction: 1\n",
            "   feature 0 = 1:\n",
            "      prediction: 0\n",
            "feature 12 = 2:\n",
            "   feature 0 = 0:\n",
            "      feature 5 = 0:\n",
            "         prediction: 2\n",
            "      feature 5 = 1:\n",
            "         feature 7 = 0:\n",
            "            prediction: 6\n",
            "         feature 7 = 1:\n",
            "            prediction: 4\n",
            "   feature 0 = 1:\n",
            "      prediction: 0\n",
            "feature 12 = 3:\n",
            "   prediction: 6\n",
            "feature 12 = 4:\n",
            "   feature 5 = 0:\n",
            "      prediction: 5\n",
            "   feature 5 = 1:\n",
            "      prediction: 6\n",
            "feature 12 = 5:\n",
            "   prediction: 6\n",
            "\n",
            "\n",
            "acc:  0.147 \n",
            "\n",
            "Split info gain\n",
            "[1.3630469031539396, 0.8865408928220901, 0.9852281360342516, 0.6962122601251458, 0.8256265261578954, 0.6892019851173655, 0.863120568566631, 0.7219280948873623, 0.7219280948873623]\n"
          ]
        }
      ],
      "source": [
        "# Load evaluation training data\n",
        "!curl -s https://raw.githubusercontent.com/cs472ta/CS472/master/datasets/zoo.arff --output zoo.arff\n",
        "    \n",
        "eval_data = arff.loadarff('zoo.arff')\n",
        "eval_df = pd.DataFrame(eval_data[0])\n",
        "\n",
        "# need to fix columns to be strings\n",
        "eval_df = convertBytestoString(eval_df)\n",
        "\n",
        "eval_df = eval_df.replace(zoo_dict)\n",
        "\n",
        "# Convert to numpy\n",
        "eval_np = eval_df.to_numpy()\n",
        "counts = get_counts(eval_df)\n",
        "\n",
        "# Train Decision Tree\n",
        "eval_clf = DTClassifier(counts=counts)\n",
        "eval_acc = eval_clf.fit_and_score(eval_np)\n",
        "eval_clf.print_tree()\n",
        "print(\"\\n\")\n",
        "\n",
        "\n",
        "# Load debug test data\n",
        "!curl -s https://raw.githubusercontent.com/cs472ta/CS472/master/datasets/zoo_test.arff --output eval_test.arff\n",
        "\n",
        "eval_test = arff.loadarff('eval_test.arff')\n",
        "eval_test_df = pd.DataFrame(eval_test[0])\n",
        "\n",
        "eval_test_df = convertBytestoString(eval_test_df)\n",
        "eval_test_df = eval_test_df.replace(zoo_dict)\n",
        "\n",
        "eval_np_test = eval_test_df.to_numpy()\n",
        "\n",
        "# Predict and compute model accuracy\n",
        "prediction = eval_clf.predict(eval_np_test[:,0:len(counts)-1])\n",
        "acc = eval_clf.score(eval_np_test[:,0:], eval_np_test[:,len(counts)-1:])\n",
        "print(\"acc: \", acc, \"\\n\")\n",
        "\n",
        "# Print the information gain of every split you make.\n",
        "print(\"Split info gain\")\n",
        "print(eval_clf.get_split_info_gain())\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pVfaMvqHCmL0"
      },
      "source": [
        "## 2. (20%) You will use your ID3 algorithm to induce decision trees for the cars dataset and the voting dataset.  Do not use a stopping criteria, but induce the tree as far as it can go (until classes are pure or there are no more data or attributes to split on).  \n",
        "- Implement and use 10-fold Cross Validation (CV) on each data set to predict how well the models will do on novel data.  \n",
        "- For each dataset, report the training and test classification accuracy for each fold and the average test accuracy. \n",
        "- As a rough sanity check, typical decision tree accuracies for these data sets are: Cars: .90-.95, Vote: .92-.95."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jQdySr-HCmL0"
      },
      "source": [
        "## 2.1 Implement 10-fold Cross Validation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "RDRcKCYjCmL1"
      },
      "outputs": [],
      "source": [
        "# Write a function that implements 10-fold cross validation\n",
        "class K_Fold_CV():\n",
        "  def __init__(self, dataset, k_val):\n",
        "    self.dataset = dataset\n",
        "    self.k_val = k_val\n",
        "    # split and shuffle is automatically called from the constructor\n",
        "    self.split_data = self.shuffle_and_split()\n",
        "\n",
        "  def shuffle_and_split(self):\n",
        "    # shuffle before folding\n",
        "    np.random.shuffle(self.dataset)\n",
        "    # initialize array for splitting\n",
        "    split_data = [[] for x in range(self.k_val)]\n",
        "    split_pointer = 0\n",
        "    # loop through dataset passed in\n",
        "    for i in range(len(self.dataset)):\n",
        "      split_data[split_pointer].append(self.dataset[i])\n",
        "      split_pointer += 1\n",
        "      # reset pointer\n",
        "      if split_pointer == self.k_val:\n",
        "        split_pointer = 0\n",
        "    return split_data\n",
        "\n",
        "  def get_datasets_at_index(self, k_index):\n",
        "    # initialize test dataset\n",
        "    t_set = []\n",
        "    for i in range(self.k_val):\n",
        "      if i != k_index:\n",
        "        for j in range(len(self.split_data[i])):\n",
        "          # append to test set\n",
        "          t_set.append(self.split_data[i][j])\n",
        "    # get validation set from split data based on k_index\n",
        "    v_set = self.split_data[k_index]\n",
        "    # convert to np array before returning\n",
        "    return np.array(t_set), np.array(v_set)\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JrurQtTTCmL1"
      },
      "source": [
        "##  2.2 Cars Dataset\n",
        "- Use this [Cars Dataset](https://raw.githubusercontent.com/cs472ta/CS472/master/datasets/cars.arff)\n",
        "- Make a table for your K-Fold cross validation accuracies\n",
        "\n",
        "*If you are having trouble using scipy's loadarff function (scipy.io.arff.loadarff), try:*\n",
        "\n",
        "*pip install arff &nbsp;&nbsp;&nbsp;&nbsp;          # Install arff library*\n",
        "\n",
        "*import arff as arf*                   \n",
        "\n",
        "*cars = list(arf.load('cars.arff'))   &nbsp;&nbsp;&nbsp;&nbsp;# Load your downloaded dataset (!curl, etc.)*\n",
        "\n",
        "*df = pd.DataFrame(cars)*  \n",
        "\n",
        "*There may be additional cleaning needed*"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "6I50wXJeCmL1"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "feature 5 = 0:\n",
            "   prediction: 0\n",
            "feature 5 = 1:\n",
            "   feature 3 = 0:\n",
            "      prediction: 0\n",
            "   feature 3 = 1:\n",
            "      feature 0 = 0:\n",
            "         feature 1 = 0:\n",
            "            prediction: 0\n",
            "         feature 1 = 1:\n",
            "            prediction: 0\n",
            "         feature 1 = 2:\n",
            "            feature 4 = 0:\n",
            "               prediction: 0\n",
            "            feature 4 = 1:\n",
            "               feature 2 = 0:\n",
            "                  prediction: 0\n",
            "               feature 2 = 1:\n",
            "                  prediction: 0\n",
            "               feature 2 = 2:\n",
            "                  prediction: 1\n",
            "               feature 2 = 3:\n",
            "                  prediction: 1\n",
            "            feature 4 = 2:\n",
            "               prediction: 1\n",
            "         feature 1 = 3:\n",
            "            feature 4 = 0:\n",
            "               prediction: 0\n",
            "            feature 4 = 1:\n",
            "               feature 2 = 0:\n",
            "                  prediction: 0\n",
            "               feature 2 = 1:\n",
            "                  prediction: 0\n",
            "               feature 2 = 2:\n",
            "                  prediction: 1\n",
            "               feature 2 = 3:\n",
            "                  prediction: 1\n",
            "            feature 4 = 2:\n",
            "               prediction: 1\n",
            "      feature 0 = 1:\n",
            "         feature 4 = 0:\n",
            "            prediction: 0\n",
            "         feature 4 = 1:\n",
            "            feature 2 = 0:\n",
            "               prediction: 0\n",
            "            feature 2 = 1:\n",
            "               prediction: 0\n",
            "            feature 2 = 2:\n",
            "               feature 1 = 0:\n",
            "                  prediction: 0\n",
            "               feature 1 = 1:\n",
            "                  prediction: 1\n",
            "               feature 1 = 2:\n",
            "                  prediction: 1\n",
            "               feature 1 = 3:\n",
            "                  prediction: 1\n",
            "            feature 2 = 3:\n",
            "               feature 1 = 0:\n",
            "                  prediction: 0\n",
            "               feature 1 = 1:\n",
            "                  prediction: 1\n",
            "               feature 1 = 2:\n",
            "                  prediction: 1\n",
            "               feature 1 = 3:\n",
            "                  prediction: 1\n",
            "         feature 4 = 2:\n",
            "            feature 1 = 0:\n",
            "               prediction: 0\n",
            "            feature 1 = 1:\n",
            "               prediction: 1\n",
            "            feature 1 = 2:\n",
            "               prediction: 1\n",
            "            feature 1 = 3:\n",
            "               prediction: 1\n",
            "      feature 0 = 2:\n",
            "         feature 1 = 0:\n",
            "            feature 4 = 0:\n",
            "               prediction: 0\n",
            "            feature 4 = 1:\n",
            "               feature 2 = 0:\n",
            "                  prediction: 0\n",
            "               feature 2 = 1:\n",
            "                  prediction: 0\n",
            "               feature 2 = 2:\n",
            "                  prediction: 1\n",
            "               feature 2 = 3:\n",
            "                  prediction: 1\n",
            "            feature 4 = 2:\n",
            "               prediction: 1\n",
            "         feature 1 = 1:\n",
            "            feature 4 = 0:\n",
            "               prediction: 0\n",
            "            feature 4 = 1:\n",
            "               feature 2 = 0:\n",
            "                  prediction: 0\n",
            "               feature 2 = 1:\n",
            "                  prediction: 0\n",
            "               feature 2 = 2:\n",
            "                  prediction: 1\n",
            "            feature 4 = 2:\n",
            "               prediction: 1\n",
            "         feature 1 = 2:\n",
            "            prediction: 1\n",
            "         feature 1 = 3:\n",
            "            feature 4 = 0:\n",
            "               prediction: 1\n",
            "            feature 4 = 1:\n",
            "               feature 2 = 0:\n",
            "                  prediction: 1\n",
            "               feature 2 = 1:\n",
            "                  prediction: 1\n",
            "               feature 2 = 2:\n",
            "                  prediction: 2\n",
            "               feature 2 = 3:\n",
            "                  prediction: 2\n",
            "            feature 4 = 2:\n",
            "               prediction: 2\n",
            "      feature 0 = 3:\n",
            "         feature 1 = 0:\n",
            "            feature 4 = 0:\n",
            "               prediction: 0\n",
            "            feature 4 = 1:\n",
            "               feature 2 = 0:\n",
            "                  prediction: 0\n",
            "               feature 2 = 1:\n",
            "                  prediction: 0\n",
            "               feature 2 = 2:\n",
            "                  prediction: 1\n",
            "               feature 2 = 3:\n",
            "                  prediction: 1\n",
            "            feature 4 = 2:\n",
            "               prediction: 1\n",
            "         feature 1 = 1:\n",
            "            prediction: 1\n",
            "         feature 1 = 2:\n",
            "            feature 4 = 0:\n",
            "               prediction: 1\n",
            "            feature 4 = 1:\n",
            "               feature 2 = 0:\n",
            "                  prediction: 1\n",
            "               feature 2 = 2:\n",
            "                  prediction: 2\n",
            "            feature 4 = 2:\n",
            "               prediction: 2\n",
            "         feature 1 = 3:\n",
            "            feature 4 = 0:\n",
            "               prediction: 1\n",
            "            feature 4 = 1:\n",
            "               feature 2 = 0:\n",
            "                  prediction: 1\n",
            "               feature 2 = 1:\n",
            "                  prediction: 1\n",
            "               feature 2 = 2:\n",
            "                  prediction: 2\n",
            "               feature 2 = 3:\n",
            "                  prediction: 2\n",
            "            feature 4 = 2:\n",
            "               prediction: 2\n",
            "   feature 3 = 2:\n",
            "      feature 4 = 0:\n",
            "         feature 0 = 0:\n",
            "            prediction: 0\n",
            "         feature 0 = 1:\n",
            "            prediction: 0\n",
            "         feature 0 = 2:\n",
            "            feature 1 = 0:\n",
            "               prediction: 0\n",
            "            feature 1 = 1:\n",
            "               prediction: 0\n",
            "            feature 1 = 2:\n",
            "               feature 2 = 0:\n",
            "                  prediction: 0\n",
            "               feature 2 = 1:\n",
            "                  prediction: 1\n",
            "               feature 2 = 3:\n",
            "                  prediction: 1\n",
            "            feature 1 = 3:\n",
            "               feature 2 = 0:\n",
            "                  prediction: 0\n",
            "               feature 2 = 1:\n",
            "                  prediction: 1\n",
            "         feature 0 = 3:\n",
            "            feature 2 = 0:\n",
            "               prediction: 0\n",
            "            feature 2 = 1:\n",
            "               prediction: 1\n",
            "            feature 2 = 2:\n",
            "               feature 1 = 0:\n",
            "                  prediction: 0\n",
            "               feature 1 = 1:\n",
            "                  prediction: 1\n",
            "               feature 1 = 2:\n",
            "                  prediction: 1\n",
            "               feature 1 = 3:\n",
            "                  prediction: 1\n",
            "            feature 2 = 3:\n",
            "               feature 1 = 0:\n",
            "                  prediction: 0\n",
            "               feature 1 = 1:\n",
            "                  prediction: 1\n",
            "               feature 1 = 2:\n",
            "                  prediction: 1\n",
            "               feature 1 = 3:\n",
            "                  prediction: 1\n",
            "      feature 4 = 1:\n",
            "         feature 1 = 0:\n",
            "            feature 0 = 0:\n",
            "               prediction: 0\n",
            "            feature 0 = 1:\n",
            "               prediction: 0\n",
            "            feature 0 = 2:\n",
            "               feature 2 = 0:\n",
            "                  prediction: 0\n",
            "               feature 2 = 2:\n",
            "                  prediction: 1\n",
            "               feature 2 = 3:\n",
            "                  prediction: 1\n",
            "            feature 0 = 3:\n",
            "               feature 2 = 0:\n",
            "                  prediction: 0\n",
            "               feature 2 = 1:\n",
            "                  prediction: 1\n",
            "               feature 2 = 2:\n",
            "                  prediction: 1\n",
            "               feature 2 = 3:\n",
            "                  prediction: 1\n",
            "         feature 1 = 1:\n",
            "            feature 2 = 0:\n",
            "               prediction: 0\n",
            "            feature 2 = 1:\n",
            "               feature 0 = 0:\n",
            "                  prediction: 0\n",
            "               feature 0 = 1:\n",
            "                  prediction: 1\n",
            "               feature 0 = 2:\n",
            "                  prediction: 1\n",
            "               feature 0 = 3:\n",
            "                  prediction: 1\n",
            "            feature 2 = 2:\n",
            "               prediction: 1\n",
            "            feature 2 = 3:\n",
            "               prediction: 1\n",
            "         feature 1 = 2:\n",
            "            feature 0 = 0:\n",
            "               feature 2 = 0:\n",
            "                  prediction: 0\n",
            "               feature 2 = 1:\n",
            "                  prediction: 1\n",
            "               feature 2 = 2:\n",
            "                  prediction: 1\n",
            "               feature 2 = 3:\n",
            "                  prediction: 1\n",
            "            feature 0 = 1:\n",
            "               feature 2 = 0:\n",
            "                  prediction: 0\n",
            "               feature 2 = 1:\n",
            "                  prediction: 1\n",
            "               feature 2 = 2:\n",
            "                  prediction: 1\n",
            "            feature 0 = 2:\n",
            "               prediction: 1\n",
            "            feature 0 = 3:\n",
            "               feature 2 = 0:\n",
            "                  prediction: 1\n",
            "               feature 2 = 1:\n",
            "                  prediction: 2\n",
            "               feature 2 = 2:\n",
            "                  prediction: 2\n",
            "               feature 2 = 3:\n",
            "                  prediction: 2\n",
            "         feature 1 = 3:\n",
            "            feature 0 = 0:\n",
            "               prediction: 1\n",
            "            feature 0 = 1:\n",
            "               prediction: 1\n",
            "            feature 0 = 2:\n",
            "               feature 2 = 0:\n",
            "                  prediction: 1\n",
            "               feature 2 = 2:\n",
            "                  prediction: 2\n",
            "               feature 2 = 3:\n",
            "                  prediction: 2\n",
            "            feature 0 = 3:\n",
            "               feature 2 = 0:\n",
            "                  prediction: 1\n",
            "               feature 2 = 1:\n",
            "                  prediction: 2\n",
            "               feature 2 = 2:\n",
            "                  prediction: 2\n",
            "               feature 2 = 3:\n",
            "                  prediction: 2\n",
            "      feature 4 = 2:\n",
            "         feature 0 = 0:\n",
            "            feature 1 = 0:\n",
            "               prediction: 0\n",
            "            feature 1 = 1:\n",
            "               prediction: 0\n",
            "            feature 1 = 2:\n",
            "               prediction: 1\n",
            "            feature 1 = 3:\n",
            "               prediction: 1\n",
            "         feature 0 = 1:\n",
            "            feature 1 = 0:\n",
            "               prediction: 0\n",
            "            feature 1 = 1:\n",
            "               prediction: 1\n",
            "            feature 1 = 2:\n",
            "               prediction: 1\n",
            "            feature 1 = 3:\n",
            "               prediction: 1\n",
            "         feature 0 = 2:\n",
            "            feature 1 = 0:\n",
            "               prediction: 1\n",
            "            feature 1 = 1:\n",
            "               prediction: 1\n",
            "            feature 1 = 2:\n",
            "               prediction: 1\n",
            "            feature 1 = 3:\n",
            "               prediction: 2\n",
            "         feature 0 = 3:\n",
            "            feature 1 = 0:\n",
            "               prediction: 1\n",
            "            feature 1 = 1:\n",
            "               prediction: 1\n",
            "            feature 1 = 2:\n",
            "               prediction: 2\n",
            "            feature 1 = 3:\n",
            "               prediction: 2\n",
            "feature 5 = 2:\n",
            "   feature 3 = 0:\n",
            "      prediction: 0\n",
            "   feature 3 = 1:\n",
            "      feature 0 = 0:\n",
            "         feature 1 = 0:\n",
            "            prediction: 0\n",
            "         feature 1 = 1:\n",
            "            prediction: 0\n",
            "         feature 1 = 2:\n",
            "            prediction: 1\n",
            "         feature 1 = 3:\n",
            "            prediction: 1\n",
            "      feature 0 = 1:\n",
            "         feature 1 = 0:\n",
            "            prediction: 0\n",
            "         feature 1 = 1:\n",
            "            prediction: 1\n",
            "         feature 1 = 2:\n",
            "            prediction: 1\n",
            "         feature 1 = 3:\n",
            "            prediction: 1\n",
            "      feature 0 = 2:\n",
            "         feature 1 = 0:\n",
            "            prediction: 1\n",
            "         feature 1 = 1:\n",
            "            prediction: 1\n",
            "         feature 1 = 2:\n",
            "            feature 4 = 0:\n",
            "               prediction: 1\n",
            "            feature 4 = 1:\n",
            "               feature 2 = 0:\n",
            "                  prediction: 1\n",
            "               feature 2 = 3:\n",
            "                  prediction: 3\n",
            "            feature 4 = 2:\n",
            "               prediction: 3\n",
            "         feature 1 = 3:\n",
            "            feature 4 = 0:\n",
            "               prediction: 2\n",
            "            feature 4 = 1:\n",
            "               feature 2 = 0:\n",
            "                  prediction: 2\n",
            "               feature 2 = 1:\n",
            "                  prediction: 2\n",
            "               feature 2 = 2:\n",
            "                  prediction: 3\n",
            "               feature 2 = 3:\n",
            "                  prediction: 3\n",
            "            feature 4 = 2:\n",
            "               prediction: 3\n",
            "      feature 0 = 3:\n",
            "         feature 1 = 0:\n",
            "            prediction: 1\n",
            "         feature 1 = 1:\n",
            "            feature 4 = 0:\n",
            "               prediction: 1\n",
            "            feature 4 = 1:\n",
            "               feature 2 = 0:\n",
            "                  prediction: 1\n",
            "               feature 2 = 1:\n",
            "                  prediction: 1\n",
            "               feature 2 = 2:\n",
            "                  prediction: 3\n",
            "               feature 2 = 3:\n",
            "                  prediction: 3\n",
            "            feature 4 = 2:\n",
            "               prediction: 3\n",
            "         feature 1 = 2:\n",
            "            feature 2 = 0:\n",
            "               feature 4 = 1:\n",
            "                  prediction: 2\n",
            "               feature 4 = 2:\n",
            "                  prediction: 3\n",
            "            feature 2 = 1:\n",
            "               prediction: 2\n",
            "            feature 2 = 2:\n",
            "               feature 4 = 0:\n",
            "                  prediction: 2\n",
            "               feature 4 = 1:\n",
            "                  prediction: 3\n",
            "            feature 2 = 3:\n",
            "               prediction: 3\n",
            "         feature 1 = 3:\n",
            "            feature 4 = 0:\n",
            "               prediction: 2\n",
            "            feature 4 = 1:\n",
            "               feature 2 = 0:\n",
            "                  prediction: 2\n",
            "               feature 2 = 2:\n",
            "                  prediction: 3\n",
            "               feature 2 = 3:\n",
            "                  prediction: 3\n",
            "            feature 4 = 2:\n",
            "               prediction: 3\n",
            "   feature 3 = 2:\n",
            "      feature 0 = 0:\n",
            "         feature 1 = 0:\n",
            "            prediction: 0\n",
            "         feature 1 = 1:\n",
            "            prediction: 0\n",
            "         feature 1 = 2:\n",
            "            feature 2 = 0:\n",
            "               feature 4 = 0:\n",
            "                  prediction: 0\n",
            "               feature 4 = 1:\n",
            "                  prediction: 1\n",
            "               feature 4 = 2:\n",
            "                  prediction: 1\n",
            "            feature 2 = 1:\n",
            "               prediction: 1\n",
            "            feature 2 = 2:\n",
            "               prediction: 1\n",
            "            feature 2 = 3:\n",
            "               prediction: 1\n",
            "         feature 1 = 3:\n",
            "            feature 2 = 0:\n",
            "               feature 4 = 0:\n",
            "                  prediction: 0\n",
            "               feature 4 = 1:\n",
            "                  prediction: 1\n",
            "               feature 4 = 2:\n",
            "                  prediction: 1\n",
            "            feature 2 = 1:\n",
            "               prediction: 1\n",
            "            feature 2 = 2:\n",
            "               prediction: 1\n",
            "            feature 2 = 3:\n",
            "               prediction: 1\n",
            "      feature 0 = 1:\n",
            "         feature 1 = 0:\n",
            "            prediction: 0\n",
            "         feature 1 = 1:\n",
            "            feature 2 = 0:\n",
            "               feature 4 = 0:\n",
            "                  prediction: 0\n",
            "               feature 4 = 1:\n",
            "                  prediction: 1\n",
            "               feature 4 = 2:\n",
            "                  prediction: 1\n",
            "            feature 2 = 1:\n",
            "               prediction: 1\n",
            "            feature 2 = 2:\n",
            "               prediction: 1\n",
            "            feature 2 = 3:\n",
            "               prediction: 1\n",
            "         feature 1 = 2:\n",
            "            feature 2 = 0:\n",
            "               feature 4 = 0:\n",
            "                  prediction: 0\n",
            "               feature 4 = 1:\n",
            "                  prediction: 1\n",
            "               feature 4 = 2:\n",
            "                  prediction: 1\n",
            "            feature 2 = 1:\n",
            "               prediction: 1\n",
            "            feature 2 = 2:\n",
            "               prediction: 1\n",
            "            feature 2 = 3:\n",
            "               prediction: 1\n",
            "         feature 1 = 3:\n",
            "            feature 2 = 0:\n",
            "               feature 4 = 0:\n",
            "                  prediction: 0\n",
            "               feature 4 = 1:\n",
            "                  prediction: 1\n",
            "               feature 4 = 2:\n",
            "                  prediction: 1\n",
            "            feature 2 = 1:\n",
            "               prediction: 1\n",
            "            feature 2 = 2:\n",
            "               prediction: 1\n",
            "            feature 2 = 3:\n",
            "               prediction: 1\n",
            "      feature 0 = 2:\n",
            "         feature 1 = 0:\n",
            "            feature 2 = 0:\n",
            "               feature 4 = 0:\n",
            "                  prediction: 0\n",
            "               feature 4 = 2:\n",
            "                  prediction: 1\n",
            "            feature 2 = 1:\n",
            "               prediction: 1\n",
            "            feature 2 = 2:\n",
            "               prediction: 1\n",
            "            feature 2 = 3:\n",
            "               prediction: 1\n",
            "         feature 1 = 1:\n",
            "            feature 2 = 0:\n",
            "               feature 4 = 0:\n",
            "                  prediction: 0\n",
            "               feature 4 = 1:\n",
            "                  prediction: 1\n",
            "               feature 4 = 2:\n",
            "                  prediction: 1\n",
            "            feature 2 = 1:\n",
            "               prediction: 1\n",
            "            feature 2 = 2:\n",
            "               prediction: 1\n",
            "            feature 2 = 3:\n",
            "               prediction: 1\n",
            "         feature 1 = 2:\n",
            "            feature 4 = 0:\n",
            "               feature 2 = 0:\n",
            "                  prediction: 0\n",
            "               feature 2 = 1:\n",
            "                  prediction: 1\n",
            "               feature 2 = 2:\n",
            "                  prediction: 1\n",
            "               feature 2 = 3:\n",
            "                  prediction: 1\n",
            "            feature 4 = 1:\n",
            "               feature 2 = 0:\n",
            "                  prediction: 1\n",
            "               feature 2 = 1:\n",
            "                  prediction: 3\n",
            "               feature 2 = 2:\n",
            "                  prediction: 3\n",
            "               feature 2 = 3:\n",
            "                  prediction: 3\n",
            "            feature 4 = 2:\n",
            "               prediction: 3\n",
            "         feature 1 = 3:\n",
            "            feature 4 = 0:\n",
            "               feature 2 = 0:\n",
            "                  prediction: 0\n",
            "               feature 2 = 1:\n",
            "                  prediction: 2\n",
            "               feature 2 = 2:\n",
            "                  prediction: 2\n",
            "               feature 2 = 3:\n",
            "                  prediction: 2\n",
            "            feature 4 = 1:\n",
            "               feature 2 = 0:\n",
            "                  prediction: 2\n",
            "               feature 2 = 1:\n",
            "                  prediction: 3\n",
            "               feature 2 = 2:\n",
            "                  prediction: 3\n",
            "               feature 2 = 3:\n",
            "                  prediction: 3\n",
            "            feature 4 = 2:\n",
            "               prediction: 3\n",
            "      feature 0 = 3:\n",
            "         feature 1 = 0:\n",
            "            feature 2 = 0:\n",
            "               feature 4 = 0:\n",
            "                  prediction: 0\n",
            "               feature 4 = 1:\n",
            "                  prediction: 1\n",
            "               feature 4 = 2:\n",
            "                  prediction: 1\n",
            "            feature 2 = 1:\n",
            "               prediction: 1\n",
            "            feature 2 = 2:\n",
            "               prediction: 1\n",
            "            feature 2 = 3:\n",
            "               prediction: 1\n",
            "         feature 1 = 1:\n",
            "            feature 4 = 0:\n",
            "               feature 2 = 0:\n",
            "                  prediction: 0\n",
            "               feature 2 = 1:\n",
            "                  prediction: 1\n",
            "               feature 2 = 2:\n",
            "                  prediction: 1\n",
            "               feature 2 = 3:\n",
            "                  prediction: 1\n",
            "            feature 4 = 1:\n",
            "               feature 2 = 0:\n",
            "                  prediction: 1\n",
            "               feature 2 = 1:\n",
            "                  prediction: 3\n",
            "            feature 4 = 2:\n",
            "               prediction: 3\n",
            "         feature 1 = 2:\n",
            "            feature 4 = 0:\n",
            "               prediction: 2\n",
            "            feature 4 = 1:\n",
            "               feature 2 = 0:\n",
            "                  prediction: 2\n",
            "               feature 2 = 1:\n",
            "                  prediction: 3\n",
            "               feature 2 = 2:\n",
            "                  prediction: 3\n",
            "               feature 2 = 3:\n",
            "                  prediction: 3\n",
            "            feature 4 = 2:\n",
            "               prediction: 3\n",
            "         feature 1 = 3:\n",
            "            feature 4 = 0:\n",
            "               feature 2 = 0:\n",
            "                  prediction: 0\n",
            "               feature 2 = 1:\n",
            "                  prediction: 2\n",
            "               feature 2 = 2:\n",
            "                  prediction: 2\n",
            "               feature 2 = 3:\n",
            "                  prediction: 2\n",
            "            feature 4 = 1:\n",
            "               feature 2 = 0:\n",
            "                  prediction: 2\n",
            "               feature 2 = 1:\n",
            "                  prediction: 3\n",
            "               feature 2 = 2:\n",
            "                  prediction: 3\n",
            "            feature 4 = 2:\n",
            "               prediction: 3\n",
            "test acc:  [0.8959537572254336, 0.9190751445086706, 0.9248554913294798, 0.9190751445086706, 0.9075144508670521, 0.9653179190751445, 0.9017341040462428, 0.9075144508670521, 0.9244186046511628, 0.9534883720930233]\n",
            "avg acc:  0.9218947439171933\n"
          ]
        }
      ],
      "source": [
        "# Use 10-fold CV on Cars Dataset\n",
        "!curl -s https://raw.githubusercontent.com/cs472ta/CS472/master/datasets/cars.arff --output cars.arff\n",
        "\n",
        "cars = list(arf.load('cars.arff'))\n",
        "cars_df = pd.DataFrame(cars, columns=car_columns)\n",
        "\n",
        "# convert bytestring columns to string columns\n",
        "cars_df = convertBytestoString(cars_df)\n",
        "\n",
        "cars_df = cars_df.replace(cars_dict)\n",
        "\n",
        "# Convert to numpy\n",
        "cars_np = cars_df.to_numpy()\n",
        "counts = get_counts(cars_df)\n",
        "\n",
        "k_splits = 10\n",
        "cv_tracter = K_Fold_CV(cars_np, k_splits)\n",
        "cv_accs = []\n",
        "\n",
        "for i in range(k_splits):\n",
        "    t_set, v_set = cv_tracter.get_datasets_at_index(i)\n",
        "    tmp_clf = DTClassifier(counts=counts)\n",
        "    tmp_clf.fit_and_score(t_set)\n",
        "    if i == 0:\n",
        "        tmp_clf.print_tree()\n",
        "    acc = tmp_clf.score(v_set[:,0:], v_set[:,len(counts)-1:])\n",
        "    cv_accs.append(acc)\n",
        "\n",
        "# Report Training and Test Classification Accuracies\n",
        "print(\"test acc: \", cv_accs)\n",
        "\n",
        "# Report Average Test Accuracy\n",
        "avg_acc = sum(cv_accs)/k_splits\n",
        "print(\"avg acc: \", avg_acc)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z93wyVhjCmL1"
      },
      "source": [
        "## 2.3 Voting Dataset\n",
        "- Use this [Voting Dataset with missing values](https://raw.githubusercontent.com/cs472ta/CS472/master/datasets/voting_with_missing.arff)\n",
        "- Note that you will need to support unknown attributes in the voting data set. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "yUNtg8LBCmL2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "feature 3 = 0:\n",
            "   feature 13 = 0:\n",
            "      prediction: 0\n",
            "   feature 13 = 1:\n",
            "      feature 10 = 0:\n",
            "         feature 2 = 0:\n",
            "            feature 11 = 0:\n",
            "               feature 0 = 0:\n",
            "                  prediction: 1\n",
            "               feature 0 = 1:\n",
            "                  feature 5 = 0:\n",
            "                     prediction: 1\n",
            "                  feature 5 = 1:\n",
            "                     prediction: 0\n",
            "            feature 11 = 1:\n",
            "               prediction: 0\n",
            "         feature 2 = 1:\n",
            "            feature 4 = 0:\n",
            "               prediction: 0\n",
            "            feature 4 = 1:\n",
            "               feature 1 = 0:\n",
            "                  prediction: 0\n",
            "               feature 1 = 1:\n",
            "                  feature 6 = 0:\n",
            "                     prediction: 0\n",
            "                  feature 6 = 1:\n",
            "                     feature 0 = 0:\n",
            "                        feature 5 = 1:\n",
            "                           feature 7 = 1:\n",
            "                              feature 8 = 1:\n",
            "                                 feature 9 = 1:\n",
            "                                    feature 11 = 0:\n",
            "                                       feature 12 = 1:\n",
            "                                          feature 14 = 0:\n",
            "                                             feature 15 = 1:\n",
            "                                                prediction: 0\n",
            "      feature 10 = 1:\n",
            "         prediction: 0\n",
            "feature 3 = 1:\n",
            "   feature 10 = 0:\n",
            "      feature 14 = 0:\n",
            "         feature 2 = 0:\n",
            "            prediction: 1\n",
            "         feature 2 = 1:\n",
            "            feature 9 = 0:\n",
            "               feature 6 = 0:\n",
            "                  prediction: 0\n",
            "               feature 6 = 1:\n",
            "                  prediction: 1\n",
            "            feature 9 = 1:\n",
            "               prediction: 1\n",
            "      feature 14 = 1:\n",
            "         feature 9 = 0:\n",
            "            feature 6 = 0:\n",
            "               feature 11 = 0:\n",
            "                  prediction: 0\n",
            "               feature 11 = 1:\n",
            "                  prediction: 1\n",
            "            feature 6 = 1:\n",
            "               prediction: 1\n",
            "         feature 9 = 1:\n",
            "            prediction: 1\n",
            "   feature 10 = 1:\n",
            "      feature 2 = 0:\n",
            "         feature 4 = 0:\n",
            "            prediction: 0\n",
            "         feature 4 = 1:\n",
            "            feature 9 = 0:\n",
            "               feature 12 = 0:\n",
            "                  prediction: 0\n",
            "               feature 12 = 1:\n",
            "                  feature 6 = 0:\n",
            "                     feature 7 = 0:\n",
            "                        feature 1 = 0:\n",
            "                           feature 0 = 0:\n",
            "                              feature 15 = 0:\n",
            "                                 prediction: 0\n",
            "                              feature 15 = 1:\n",
            "                                 prediction: 1\n",
            "                           feature 0 = 1:\n",
            "                              prediction: 1\n",
            "                        feature 1 = 1:\n",
            "                           feature 0 = 0:\n",
            "                              prediction: 1\n",
            "                           feature 0 = 1:\n",
            "                              feature 11 = 0:\n",
            "                                 feature 5 = 1:\n",
            "                                    feature 8 = 0:\n",
            "                                       feature 13 = 1:\n",
            "                                          feature 14 = 0:\n",
            "                                             feature 15 = 1:\n",
            "                                                prediction: 1\n",
            "                              feature 11 = 1:\n",
            "                                 prediction: 1\n",
            "                     feature 7 = 1:\n",
            "                        prediction: 1\n",
            "                  feature 6 = 1:\n",
            "                     prediction: 1\n",
            "            feature 9 = 1:\n",
            "               prediction: 1\n",
            "      feature 2 = 1:\n",
            "         feature 6 = 0:\n",
            "            prediction: 0\n",
            "         feature 6 = 1:\n",
            "            prediction: 1\n",
            "test acc:  [0.9318181818181818, 0.9772727272727273, 0.8863636363636364, 0.9545454545454546, 0.9090909090909091, 0.9069767441860465, 0.9767441860465116, 0.9302325581395349, 0.9534883720930233, 0.9069767441860465]\n",
            "avg acc:  0.9333509513742072\n"
          ]
        }
      ],
      "source": [
        "# Used 10-fold CV on Voting Dataset\n",
        "!curl -s https://raw.githubusercontent.com/cs472ta/CS472/master/datasets/voting_with_missing.arff --output voting.arff\n",
        "\n",
        "voting_data = arff.loadarff(\"voting.arff\")\n",
        "\n",
        "voting_df = pd.DataFrame(voting_data[0])\n",
        "voting_df = convertBytestoString(voting_df)\n",
        "\n",
        "voting_df = voting_df.replace(voting_dict)\n",
        "\n",
        "# Convert to numpy\n",
        "voting_np = handle_missing(voting_df).astype(int)\n",
        "counts = get_counts(voting_df)\n",
        "\n",
        "k_splits = 10\n",
        "cv_tracter = K_Fold_CV(voting_np, k_splits)\n",
        "cv_accs = []\n",
        "\n",
        "# starting CV loop \n",
        "for i in range(k_splits):\n",
        "    t_set, v_set = cv_tracter.get_datasets_at_index(i)\n",
        "    tmp_clf = DTClassifier(counts=counts)\n",
        "    tmp_clf.fit_and_score(t_set)\n",
        "    if i == 0:\n",
        "        tmp_clf.print_tree()\n",
        "    acc = tmp_clf.score(v_set[:,0:], v_set[:,len(counts)-1:])\n",
        "    cv_accs.append(acc)\n",
        "\n",
        "# Report Training and Test Classification Accuracies\n",
        "print(\"test acc: \", cv_accs)\n",
        "\n",
        "# Report Average Test Accuracy\n",
        "avg_acc = sum(cv_accs)/k_splits\n",
        "print(\"avg acc: \", avg_acc)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yBzLv0l-CmL2"
      },
      "source": [
        "## 2.4 Discuss Your Results\n",
        "\n",
        "- Summarize your results from both datasets, and discuss what you observed. \n",
        "- A fully expanded tree will often get 100% accuracy on the training set. Why does this happen and in what cases might it not?  "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iLJq3SCcCmL2"
      },
      "source": [
        "Discuss your results"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gCi8FgyzCmL2"
      },
      "source": [
        "## 3. (15%) For each of the two problems above, summarize in English what the decision tree has learned (i.e. look at the induced tree and describe what rules it has discovered to try to solve each task). \n",
        "- If the tree is very large you can just discuss a few of the more shallow attribute combinations and the most important decisions made high in the tree."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JUO9beTOCmL2"
      },
      "source": [
        "## 3.1 Discuss what the decision tree induced on the cars dataset has learned"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lxJsPkQkCmL3"
      },
      "source": [
        "Discussion Here"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ip5zeIIFCmL3"
      },
      "source": [
        "## 3.2 Discuss what the decision tree induced on the voting dataset has learned"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BlUsN_SfCmL3"
      },
      "source": [
        "Discussion Here"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JGLflx_FCmL3"
      },
      "source": [
        "## 3.3 How did you handle unknown attributes in the voting problem? Why did you choose this approach? (Do not use the approach of just throwing out data with unknown attributes)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3YmvT4T7CmL3"
      },
      "source": [
        "Discuss how you handled unknown attributes"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Bszs7X95CmL3"
      },
      "source": [
        "## 4.1 (10%) Use SciKit Learn's decision tree on the voting dataset and compare your results. Try different parameters and report what parameters perform the best on the test set. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9EptPkscCmL3"
      },
      "source": [
        "### 4.1.1 SK Learn on Voting Dataset\n",
        "- Use this [Voting Dataset with missing values](https://raw.githubusercontent.com/cs472ta/CS472/master/datasets/voting_with_missing.arff)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xpvOixmjCmL4"
      },
      "outputs": [],
      "source": [
        "# Use SK Learn's Decision Tree to learn the voting dataset\n",
        "\n",
        "# Explore different parameters\n",
        "\n",
        "# Report results"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ByCPKa5vCmL4"
      },
      "source": [
        "Discuss results & compare to your method's results"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "taIOEaWCCmL4"
      },
      "source": [
        "## 4.2 (10%) Choose a data set of your choice (not already used in this or previous labs) and use the SK decision tree to learn it. Experiment with different hyper-parameters to try to get the best results possible."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MU2XN8cOCmL4"
      },
      "outputs": [],
      "source": [
        "# Use SciKit Learn's Decision Tree on a new dataset\n",
        "\n",
        "# Experiment with different hyper-parameters"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CbAEEv1RCmL4"
      },
      "source": [
        "## 5. (5%) Visualize sklearn's decision tree for your chosen data set (using export_graphviz or another tool) and discuss what you find. If your tree is too deep to reasonably fit on one page, show only the first several levels (e.g. top 5)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dXH8-BD2CmL4"
      },
      "outputs": [],
      "source": [
        "# Include decision tree visualization here\n",
        "\n",
        "# Discuss what the model has learned"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vfAQCjEbCmL4"
      },
      "source": [
        "## 6. (optional 5% extra credit) Implement reduced error pruning to help avoid overfitting.  \n",
        "- You will need to take a validation set out of your training data to do this, while still having a test set to test your final accuracy. \n",
        "- Create a table comparing your decision tree implementation's results on the cars and voting data sets with and without reduced error pruning. \n",
        "- This table should compare:\n",
        "    - a) The # of nodes (including leaf nodes) and tree depth of the final decision trees \n",
        "    - b) The generalization (test set) accuracy. (For the unpruned 10-fold CV models, just use their average values in the table)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iSdw7W9fCmL4"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "name": "lab_3_decision_tree.ipynb",
      "provenance": []
    },
    "interpreter": {
      "hash": "bf6171e0b005234b90bf150e7dae75bb4dd3ef3eda0e7c742cc9ee610eeebd82"
    },
    "kernelspec": {
      "display_name": "Python 3.9.1 64-bit ('.venv': venv)",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.1"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
