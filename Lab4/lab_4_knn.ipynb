{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DVL7_bgmIAPR"
      },
      "source": [
        "# K-Nearest Neighbor Lab\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "6ZbYjZZZ_yLV"
      },
      "outputs": [],
      "source": [
        "from sklearn.base import BaseEstimator, ClassifierMixin\n",
        "from sklearn.neighbors import KNeighborsClassifier, KNeighborsRegressor\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "# import matplotlib.pyplot as plt\n",
        "from scipy.io import arff\n",
        "from scipy.spatial import distance\n",
        "import math\n",
        "from scipy.spatial import distance\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sCcEPx5VIORj"
      },
      "source": [
        "## 1. (40%) Correctly implement the k-nearest neighbor (KNN) algorithm and the KNN regression algorithm\n",
        "\n",
        "### Code requirements\n",
        "- Use Euclidean distance to decide closest neighbors. \n",
        "- Include optional distance weighting for both algorithms\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "metadata": {
        "id": "_a2KSZ_7AN0G"
      },
      "outputs": [],
      "source": [
        "class KNNClassifier(BaseEstimator,ClassifierMixin):\n",
        "    def __init__(self, columntype='categoritcal', weight_type='inverse_distance', k_val=3): ## add parameters here\n",
        "        \"\"\"\n",
        "        Args:\n",
        "            columntype for each column tells you if continues[real] or if nominal[categoritcal].\n",
        "            weight_type: inverse_distance voting or if non distance weighting. Options = [\"no_weight\",\"inverse_distance\"]\n",
        "        \"\"\"\n",
        "        self.columntype = columntype #Note This won't be needed until part 5\n",
        "        self.weight_type = weight_type\n",
        "        self.k_val = k_val\n",
        "\n",
        "    def fit(self, data, labels):\n",
        "        \"\"\" Fit the data; run the algorithm (for this lab really just saves the data :D)\n",
        "        Args:\n",
        "            X (array-like): A 2D numpy array with the training data, excluding targets\n",
        "            y (array-like): A 2D numpy array with the training targets\n",
        "        Returns:\n",
        "            self: this allows this to be chained, e.g. model.fit(X,y).predict(X_test)\n",
        "        \"\"\"\n",
        "        self.train_data = data\n",
        "        self.train_labels = labels\n",
        "        return self\n",
        "    \n",
        "    def predict(self, data):\n",
        "        \"\"\" Predict all classes for a dataset X\n",
        "        Args:\n",
        "            X (array-like): A 2D numpy array with the training data, excluding targets\n",
        "        Returns:\n",
        "            array, shape (n_samples,)\n",
        "                Predicted target values per element in X.\n",
        "        \"\"\"\n",
        "\n",
        "        preds = []\n",
        "        for i in range(len(data)):\n",
        "            k_nearest = [[math.inf, 0] for x in range(self.k_val)]\n",
        "            dist_arr = []\n",
        "            for j in range(len(self.train_data)):\n",
        "                vals = self.train_data[j]\n",
        "                label = self.train_labels[j]\n",
        "                dist = distance.euclidean(vals, data[i])\n",
        "                dist_arr.append(dist)\n",
        "                for k in range(self.k_val):\n",
        "                    if dist < k_nearest[k][0]:\n",
        "                        k_near_copy = k_nearest.copy()\n",
        "                        for indx in range(k, self.k_val-1):\n",
        "                            old_k = k_near_copy[indx]\n",
        "                            k_nearest[indx+1] = old_k\n",
        "                        new_k = [dist, label]\n",
        "                        k_nearest[k] = new_k\n",
        "                        break\n",
        "            preds.append(self.predict_output(k_nearest))\n",
        "        return preds\n",
        "\n",
        "    def predict_output(self, k_near):\n",
        "        votes = {}\n",
        "        # if predict val is real, do regression\n",
        "        if self.columntype == 'real':\n",
        "            for i in range(len(k_near)):\n",
        "                label = k_near[i][1]\n",
        "                dist =  k_near[i][0]\n",
        "                if label in votes:\n",
        "                    if self.weight_type == 'inverse_distance':\n",
        "                        votes[label] += dist\n",
        "                    else:\n",
        "                        votes[label] = dist\n",
        "                else:\n",
        "                    if self.weight_type == 'inverse_distance':\n",
        "                        votes[label] = dist\n",
        "                    else:\n",
        "                        votes[label] = dist\n",
        "            if self.columntype == 'real':\n",
        "                if self.weight_type != 'inverse_distance':\n",
        "                    num = 0\n",
        "                    for key, value in votes.items():\n",
        "                        num+=key\n",
        "                    return num/len(votes)\n",
        "        else:\n",
        "            for i in range(len(k_near)):\n",
        "                label = k_near[i][1]\n",
        "                dist =  k_near[i][0]\n",
        "                if label in votes:\n",
        "                    if self.weight_type == 'inverse_distance':\n",
        "                        inv_dist = 1/dist**2\n",
        "                        votes[label] += inv_dist\n",
        "                    else:\n",
        "                        votes[label] +=1\n",
        "                else:\n",
        "                    if self.weight_type == 'inverse_distance':\n",
        "                        inv_dist = 1/dist**2\n",
        "                        votes[label] = inv_dist\n",
        "                    else:\n",
        "                        votes[label] = 1\n",
        "\n",
        "            max_val = 0\n",
        "            label = ''\n",
        "            for key, value in votes.items():\n",
        "                if value > max_val or max_val == 0:\n",
        "                    label = key\n",
        "                    max_val = value\n",
        "                # tie\n",
        "                elif value == max_val:\n",
        "                    label = min(key, label)\n",
        "                    max_val = value = votes[label]\n",
        "\n",
        "        return label\n",
        "\n",
        "    #Returns the Mean score given input data and labels\n",
        "    def score(self, X, y):\n",
        "        \"\"\" Return accuracy of model on a given dataset. Must implement own score function.\n",
        "        Args:\n",
        "            X (array-like): A 2D numpy array with data, excluding targets\n",
        "            y (array-like): A 2D numpy array with targets\n",
        "        Returns:\n",
        "            score : float\n",
        "                Mean accuracy of self.predict(X) wrt. y.\n",
        "        \"\"\"\n",
        "        predictions = self.predict(X)\n",
        "        correct = 0\n",
        "        for i, pred in enumerate(predictions):\n",
        "            if pred == y[i]:\n",
        "                correct +=1\n",
        "        return correct/len(X)\n",
        "    "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fEDzK14Wpj8H"
      },
      "source": [
        "## 1.1 Debug and Evaluation\n",
        "\n",
        "Debug and Evaluate your model using the parameters below:\n",
        "\n",
        "- Use distance weighting\n",
        "- KNN = 3 (three nearest neighbors)\n",
        "- Don’t normalize the data\n",
        "- Use Euclidean Distance\n",
        "\n",
        "---\n",
        "\n",
        "### 1.1.1 Debug\n",
        "\n",
        "- Use this [training set](https://raw.githubusercontent.com/cs472ta/CS472/master/datasets/glass_train.arff) and this [test set](https://raw.githubusercontent.com/cs472ta/CS472/master/datasets/glass_test.arff)\n",
        "- Use distance weighting\n",
        "- KNN = 3 (three nearest neighbors)\n",
        "- Don’t normalize the data\n",
        "- Use Euclidean Distance\n",
        "\n",
        "Expected Results:\n",
        "- Not using inverse weighted distancing = roughly [68.29%]\n",
        "- Link to [debug solution](https://github.com/cs472ta/CS472/blob/master/debug_solutions/glass_no_inv_predictions.txt)\n",
        "\n",
        "- Using inverse weighted distancing = roughly [74.39%]\n",
        "- Link to [debug solution](https://github.com/cs472ta/CS472/blob/master/debug_solutions/glass_inv_predictions.txt)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {},
      "outputs": [],
      "source": [
        "def convertBytestoString(df):\n",
        "  for col in df:\n",
        "    if isinstance(df[col][0], bytes):\n",
        "      df[col] = df[col].str.decode(\"utf8\")\n",
        "  return df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "id": "F6CAyEJopj8I"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "acc not using weighted distancing:  0.6829268292682927\n",
            "acc using weighted distancing:  0.7439024390243902\n"
          ]
        }
      ],
      "source": [
        "# Load glass data\n",
        "!curl -s https://raw.githubusercontent.com/cs472ta/CS472/master/datasets/glass_train.arff --output debug.arff\n",
        "# Train on training set\n",
        "data = arff.loadarff('debug.arff')\n",
        "debug_df = convertBytestoString(pd.DataFrame(data[0]))\n",
        "debug_np = np.array(debug_df)\n",
        "clf = KNNClassifier(weight_type='no_weight')\n",
        "train = np.array(debug_np[:,0:-1])\n",
        "targets = np.array(debug_np[:,-1])\n",
        "res = clf.fit(train, targets)\n",
        "\n",
        "\n",
        "# Predict on test set\n",
        "!curl -s https://raw.githubusercontent.com/cs472ta/CS472/master/datasets/glass_test.arff --output debug_test.arff\n",
        "debug_test = arff.loadarff('debug_test.arff')\n",
        "debug_test_df = convertBytestoString(pd.DataFrame(debug_test[0]))\n",
        "debug_test_np = np.array(debug_test_df)\n",
        "test_labels = debug_test_np[:,0:-1]\n",
        "test_targets = debug_test_np[:,-1]\n",
        "acc = res.score(test_labels, test_targets)\n",
        "print('acc not using weighted distancing: ', acc)\n",
        "\n",
        "# using inverse weighted distancing\n",
        "clf = KNNClassifier(weight_type='inverse_distance')\n",
        "iw_res = clf.fit(train, targets)\n",
        "iw_acc = iw_res.score(test_labels, test_targets)\n",
        "print('acc using weighted distancing: ', iw_acc)\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gxbxlFzjpj8I"
      },
      "source": [
        "### 1.1.2 Evaluate\n",
        "\n",
        "We will evaluate your model based on its performance on the [diabetes](https://archive.ics.uci.edu/ml/datasets/Diabetes) problem.\n",
        "- Use this [training set](https://raw.githubusercontent.com/cs472ta/CS472/master/datasets/diabetes_train.arff) and this [test set](https://raw.githubusercontent.com/cs472ta/CS472/master/datasets/diabetes_test.arff)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZydqKufipj8J"
      },
      "outputs": [],
      "source": [
        "# Load diabetes data\n",
        "\n",
        "# Train on training set\n",
        "\n",
        "# Predict on test set\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {},
      "outputs": [],
      "source": [
        "def normalize_vals(inputs):\n",
        "  xmin = inputs.min(axis=0)\n",
        "  xmax = inputs.max(axis=0)\n",
        "  return (inputs-xmin)/(xmax-xmin)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9vWiTdlbR2Xh"
      },
      "source": [
        "## 2. (10%) Use the k-nearest neighbor algorithm (without distance weighting) for the [magic telescope](http://archive.ics.uci.edu/ml/datasets/MAGIC+Gamma+Telescope) problem\n",
        "\n",
        "- Use this [training set](https://raw.githubusercontent.com/cs472ta/CS472/master/datasets/magic_telescope_train.arff) and this [test set](https://raw.githubusercontent.com/cs472ta/CS472/master/datasets/magic_telescope_test.arff) \n",
        "\n",
        "### 2.1\n",
        "- Try it with k=3 and without normalization\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4SSoasDQSKXb"
      },
      "outputs": [],
      "source": [
        "# Load magic telescope data\n",
        "\n",
        "# Train/Predict without normalization\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HDankjHLpj8L"
      },
      "source": [
        "### 2.2\n",
        "- Try it with k=3 and with normalization (input features normalized between 0 and 1). Use the normalization formula (x-xmin)/(xmax-xmin)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EAb2ot8qpj8L"
      },
      "outputs": [],
      "source": [
        "# Train/Predict with normalization\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WI0BWb9epj8M"
      },
      "source": [
        "*Discuss the accuracy results of using normalized data vs. unnormalized data*"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l_yormHgpj8N"
      },
      "source": [
        "### 2.3\n",
        "\n",
        "- Using your normalized data, create one graph with classification accuracy on the test set over k values. \n",
        "    - Use odd values of k from 1 to 15.\n",
        "- As a rough sanity check, typical knn accuracies for the magic telescope data set are 75-85%"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "v3PBKAmepj8N"
      },
      "outputs": [],
      "source": [
        "# Train/Predict with normalization using k=1,3,...,15\n",
        "\n",
        "# Graph classification accuracy over k\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HcuWW3gWpj8O"
      },
      "source": [
        "# For the rest of the experiments use only normalized data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SIRG42TgSR4x"
      },
      "source": [
        "## 3. (10%) Use the regression variation of your algorithm (without distance weighting) for the [housing price prediction](https://www.cs.toronto.edu/~delve/data/boston/bostonDetail.html) problem.\n",
        "\n",
        "- Use this [training set](https://raw.githubusercontent.com/cs472ta/CS472/master/datasets/housing_train.arff) and this [test set](https://raw.githubusercontent.com/cs472ta/CS472/master/datasets/housing_test.arff).\n",
        "- Use Mean Square Error (MSE) on the test set as your accuracy metric for this case.\n",
        "    - Do not normalize regression output values\n",
        "- Graph MSE on the test set with odd values of k from 1 to 15\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 47,
      "metadata": {
        "id": "KBGUn43ASiXW"
      },
      "outputs": [
        {
          "ename": "ValueError",
          "evalue": "operands could not be broadcast together with shapes (13,) (9,) ",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m/var/folders/y9/rp3lsyjd533_jp_d_rbnbl9r0000gn/T/ipykernel_25431/4028169354.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[0mtest_train\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnorm_test_inputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[0mtest_targets\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhousing_test_np\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 25\u001b[0;31m \u001b[0macc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mres\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscore\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_labels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_targets\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     26\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'acc not using weighted distancing: '\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0macc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/var/folders/y9/rp3lsyjd533_jp_d_rbnbl9r0000gn/T/ipykernel_25431/2823475094.py\u001b[0m in \u001b[0;36mscore\u001b[0;34m(self, X, y)\u001b[0m\n\u001b[1;32m    115\u001b[0m                 \u001b[0mMean\u001b[0m \u001b[0maccuracy\u001b[0m \u001b[0mof\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0mwrt\u001b[0m\u001b[0;34m.\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    116\u001b[0m         \"\"\"\n\u001b[0;32m--> 117\u001b[0;31m         \u001b[0mpredictions\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    118\u001b[0m         \u001b[0mcorrect\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    119\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpred\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpredictions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/var/folders/y9/rp3lsyjd533_jp_d_rbnbl9r0000gn/T/ipykernel_25431/2823475094.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, data)\u001b[0m\n\u001b[1;32m     38\u001b[0m                 \u001b[0mvals\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_data\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mj\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     39\u001b[0m                 \u001b[0mlabel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_labels\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mj\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 40\u001b[0;31m                 \u001b[0mdist\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdistance\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meuclidean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvals\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     41\u001b[0m                 \u001b[0mdist_arr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     42\u001b[0m                 \u001b[0;32mfor\u001b[0m \u001b[0mk\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mk_val\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m~/Desktop/Fall2021/CS472/CS472-Labs/.venv/lib/python3.9/site-packages/scipy/spatial/distance.py\u001b[0m in \u001b[0;36meuclidean\u001b[0;34m(u, v, w)\u001b[0m\n\u001b[1;32m    595\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    596\u001b[0m     \"\"\"\n\u001b[0;32m--> 597\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mminkowski\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mu\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mv\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mp\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mw\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mw\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    598\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    599\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m~/Desktop/Fall2021/CS472/CS472-Labs/.venv/lib/python3.9/site-packages/scipy/spatial/distance.py\u001b[0m in \u001b[0;36mminkowski\u001b[0;34m(u, v, p, w)\u001b[0m\n\u001b[1;32m    486\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mp\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    487\u001b[0m         \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"p must be at least 1\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 488\u001b[0;31m     \u001b[0mu_v\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mu\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mv\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    489\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mw\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    490\u001b[0m         \u001b[0mw\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_validate_weights\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mw\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: operands could not be broadcast together with shapes (13,) (9,) "
          ]
        }
      ],
      "source": [
        "# Load housing price prediction data\n",
        "\n",
        "# Train/Predict using k=1,3,...,15\n",
        "\n",
        "# Graph MSE over k\n",
        "\n",
        "!curl -s https://raw.githubusercontent.com/cs472ta/CS472/master/datasets/housing_train.arff --output housing.arff\n",
        "housing = arff.loadarff('housing.arff')\n",
        "housing_df = convertBytestoString(pd.DataFrame(housing[0]))\n",
        "housing_np = np.array(housing_df).astype(float)\n",
        "clf = KNNClassifier(columntype='real', weight_type='no_weight')\n",
        "norm_inputs = normalize_vals(housing_np[:,0:-1])\n",
        "train = np.array(norm_inputs)\n",
        "targets = np.array(housing_np[:,-1])\n",
        "res = clf.fit(train, targets)\n",
        "\n",
        "\n",
        "!curl -s https://raw.githubusercontent.com/cs472ta/CS472/master/datasets/housing_test.arff --output housing_test.arff\n",
        "housing_test = arff.loadarff('housing_test.arff')\n",
        "housing_test_df = convertBytestoString(pd.DataFrame(housing_test[0]))\n",
        "housing_test_np = np.array(housing_test_df).astype(float)\n",
        "norm_test_inputs = normalize_vals(housing_test_np[:,0:-1])\n",
        "test_train = np.array(norm_test_inputs)\n",
        "test_targets = np.array(housing_test_np[:,-1])\n",
        "acc = res.score(test_labels, test_targets)\n",
        "print('acc not using weighted distancing: ', acc)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v19fpixqTe-7"
      },
      "source": [
        "## 4. (15%) Repeat your experiments for magic telescope and housing using distance-weighted (inverse of distance squared) voting and discuss your results.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KkuX9RPEpj8P"
      },
      "source": [
        "## 4.1 Magic Telescope Dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZCPFUAGTS2sX"
      },
      "outputs": [],
      "source": [
        "# Train/Predict magic telescope using distance-weighted voting"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "APz2NlNepj8P"
      },
      "source": [
        "## 4.2 Housing Dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eGxzfVvNpj8P"
      },
      "outputs": [],
      "source": [
        "# Train/Predict housing using distance-weighted voting"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BoOLKUSnpj8Q"
      },
      "source": [
        "*Discuss your results*"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hhFe-C_ipj8Q"
      },
      "source": [
        "## 5. (10%) Use the k-nearest neighbor algorithm to solve the [credit-approval](https://archive.ics.uci.edu/ml/datasets/Credit+Approval) (credit-a) problem.\n",
        "\n",
        "- Use this [dataset](https://raw.githubusercontent.com/cs472ta/CS472/master/datasets/credit_approval.arff)\n",
        "    - Use a 70/30 split of the data for the training/test set\n",
        "- Note that this set has both continuous and nominal attributes, together with don’t know values. \n",
        "- Implement and justify a distance metric which supports continuous, nominal, and don’t know attribute values\n",
        "    - You need to handle don't knows with the distance metric, not by imputing a value.\n",
        "    - More information on distance metrics can be found [here](https://www.jair.org/index.php/jair/article/view/10182/24168).\n",
        "- Use your own choice for k.\n",
        "- As a rough sanity check, typical knn accuracies for the credit data set are 70-80%.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Tkz2k5Dzpj8Q"
      },
      "outputs": [],
      "source": [
        "# Load dataset and split into train/test sets\n",
        "\n",
        "# Train/Predict credit-approval\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nOIBMx8Rpj8Q"
      },
      "source": [
        "*Explain and justify your distance metric*"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oBBmeNQ7jvcQ"
      },
      "source": [
        "## 6. (15%) Use the scikit's KNN Classifier on magic telescope and KNN Regressor on housing and compare your results.\n",
        "\n",
        "- Try out different hyperparameters to see how well you can do. \n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OFQv70W2VyqJ"
      },
      "outputs": [],
      "source": [
        "# Train/Predict magic telescope using scikit's KNN\n",
        "\n",
        "# Train/Predict housing using scikit's KNN\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BqSFAXwlk3Ms"
      },
      "source": [
        "*Report your comparison*"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cTlK-kijk8Mg"
      },
      "source": [
        "## 7. (optional 5% extra credit): For the best value of k for any one of the datasets, implement a reduction algorithm that removes data points in some rational way such that performance does not drop too drastically on the test set given the reduced training set.\n",
        "\n",
        "- Compare your performance on the test set for the reduced and non-reduced versions and give the number (and percentage) of training examples removed from the original training set. How well does your reduction algorithm work?\n",
        "    - Note that performance for magic telescope is classification accuracy and for housing it is mean squared error.\n",
        "    - Magic Telescope has about 12,000 instances and if you use a leave one out style of testing for your data set reduction, then your algorithm will run slow since that is n2 at each step.\n",
        "    - If you wish, you may use a random subset of 2,000 of the magic telescope instances.\n",
        "    - More information on reduction techniques can be found [here](http://axon.cs.byu.edu/~martinez/classes/478/slides/IBL.pdf).\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5iY77P7gk1Nh"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "name": "lab_4_knn",
      "provenance": []
    },
    "interpreter": {
      "hash": "8714eab89ae485900fa73f399cda1640b5bb7d68dc82ec2a5597c91e33d54393"
    },
    "kernelspec": {
      "display_name": "Python 3.9.2 64-bit ('.venv': venv)",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.2"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
